{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Lane Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image, cmap=\"gray\", text=\"\"):\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.text(0,image.shape[0]*1.25,text)\n",
    "        plt.show()\n",
    "        \n",
    "def binary_threshold_channel(channel, thresh=(90,255)):\n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def compute_radius_of_curvature(fit, y):\n",
    "    A,B,C = fit\n",
    "    return ((1 + (2*A*y + B)**2)**1.5) / np.absolute(2*A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calibrate(path='./camera_cal/calibration*.jpg'):\n",
    "    image_paths = glob.glob(path)\n",
    "    imagepoints = []\n",
    "    objpoints = []\n",
    "\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    for image_path in image_paths:\n",
    "        # print(\"processing {}\".format(image_path))\n",
    "        image = read_image(image_path)\n",
    "        img = image.copy()\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        show_image(image, text=\"Gray Scale Image\")\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        corner_ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # If found, draw corners\n",
    "        if corner_ret == True:\n",
    "        # Draw and display the corners\n",
    "            imagepoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            cv2.drawChessboardCorners(image, (nx, ny), corners, corner_ret)\n",
    "\n",
    "            show_image(img, text=\"Distored Image\")\n",
    "\n",
    "            # * Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imagepoints, img.shape[1::-1], None, None)\n",
    "\n",
    "            undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "            show_image(undistorted, text=\"Undistorted\")\n",
    "\n",
    "            src = np.float32([corners[0],corners[8],corners[35],corners[27]])\n",
    "\n",
    "            w, h = img.shape[1::-1]\n",
    "\n",
    "            top = 0.1; bottom = 0.55; left = 0.1; right = 0.9\n",
    "\n",
    "            dst = np.float32([[w*left, h*top],[w*right, h*top],[w*right, h*bottom],[w*left, h*bottom]])\n",
    "\n",
    "            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "            # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "            warped = cv2.warpPerspective(undistorted, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "            show_image(warped, text=\"Perspective Warped image\")\n",
    "\n",
    "    calibration_values = {\n",
    "        'imgpoints': imagepoints,\n",
    "        'objpoints': objpoints,\n",
    "        'mtx_distortion_correction': mtx,\n",
    "        'distortion_coefficient': dist\n",
    "    }\n",
    "    pickle.dump(calibration_values, open( \"calibration_values.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from line import Line\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "show_image_bool=False\n",
    "def show_image(image, cmap=\"gray\", text=\"\"):\n",
    "    if show_image_bool:\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.text(0,image.shape[0]*1.25,text)\n",
    "        plt.show()\n",
    "        \n",
    "def binary_threshold_channel(channel, thresh=(100,255)):\n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def binary_threshold_channel_flip(channel, thresh=(90,255)):\n",
    "    binary = np.ones_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 0\n",
    "    return binary\n",
    "\n",
    "def compute_radius_of_curvature(fit, y):\n",
    "    A,B,C = fit\n",
    "    return ((1 + (2*A*y + B)**2)**1.5) / np.absolute(2*A)\n",
    "\n",
    "CONFIG = {\n",
    "    'mask': {\n",
    "        'lt_y': 0.6,\n",
    "        'lt_x': 0.49,\n",
    "        'rt_y': 0.6,\n",
    "        'rt_x': 0.545,\n",
    "\n",
    "        'lb_x': 0.18,\n",
    "        'lb_y': 1,        \n",
    "        'rb_x': 0.93,\n",
    "        'rb_y': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class Pipeline:        \n",
    "    def __init__(self):\n",
    "        self.calibration_values = pickle.load(open('calibration_values.p','rb'))\n",
    "        self.mtx = self.calibration_values['mtx_distortion_correction']\n",
    "        self.dist_coeff = self.calibration_values['distortion_coefficient']\n",
    "        self.perspective_transform_matrix = None\n",
    "        self.original_image = None\n",
    "        self.image = None\n",
    "        self.left_lane = Line()\n",
    "        self.right_lane = Line()\n",
    "        self.result_image = None\n",
    "        self.image_hls = None\n",
    "        self.empty_channel = None\n",
    "    \n",
    "    def convert_to_grayscale(self, image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    def read_image(self, image):\n",
    "        if type(image) == str:\n",
    "            self.original_image = cv2.imread(os.path.realpath(image))\n",
    "            self.convert_bgr_2_rgb()\n",
    "        else:\n",
    "            self.original_image = image\n",
    "        self.image = self.original_image.copy()\n",
    "        self.empty_channel = np.zeros_like(self.original_image[:,:,0])\n",
    "        \n",
    "    def convert_bgr_2_rgb(self):\n",
    "        self.original_image = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    def convert_rgb_2_hls(self):\n",
    "        self.image_hls = cv2.cvtColor(self.image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    def canny(self, image, low_threshold=50, high_threshold=150):\n",
    "        \"\"\"Applies the Canny transform\"\"\"\n",
    "        return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "    def gaussian_blur(self, image, kernel_size=5):\n",
    "        \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    def show_image(self, text=\"\", cmap=\"gray\"):\n",
    "        image = self.image\n",
    "        show_image(image, text=text, cmap=cmap)\n",
    "    \n",
    "    def undistort(self):\n",
    "        self.image = cv2.undistort(self.image, self.mtx, self.dist_coeff, None, self.mtx)\n",
    "        \n",
    "    def abs_sobel_thresh(self, orient='x', sobel_kernel=3, thresh=(0, 255)):    \n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        gray = self.convert_to_grayscale(self.image)\n",
    "\n",
    "        # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "        if orient == \"x\":\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        elif orient == \"y\":\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "        # 3) Take the absolute value of the derivative or gradient\n",
    "        abs_sobel = np.absolute(sobel)\n",
    "\n",
    "        # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "        # 5) Create a mask of 1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "        # 6) Return this mask as your binary_output image\n",
    "        return sxbinary\n",
    "\n",
    "    def mag_thresh(self, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        gray = self.convert_to_grayscale(self.image)\n",
    "\n",
    "        # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        sobel = np.sqrt(np.multiply(sobelx,sobelx) + np.multiply(sobely,sobely))\n",
    "\n",
    "        # 3) Take the absolute value of the derivative or gradient\n",
    "        abs_sobel = np.absolute(sobel)\n",
    "\n",
    "        # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "        # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "                # is > thresh_min and < thresh_max\n",
    "        binary = np.zeros_like(scaled_sobel)\n",
    "        binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "        # 6) Return this mask as your binary_output image\n",
    "        return binary\n",
    "\n",
    "    def dir_thresh(self, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        gray = self.convert_to_grayscale(self.image)\n",
    "\n",
    "        # 2) Take the gradient in x and y separately\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "        # 3) Take the absolute value of the x and y gradients\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "\n",
    "        # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "        abs_grad = np.uint8(np.arctan2(abs_sobely, abs_sobelx))\n",
    "\n",
    "        # 5) Create a binary mask where direction thresholds are met\n",
    "        binary = np.zeros_like(abs_grad)\n",
    "        binary[(abs_grad >= thresh[0]) & (abs_grad <= thresh[1])] = 1    \n",
    "        return binary\n",
    "    \n",
    "    def color_gradient_threshold_transform(self):\n",
    "        # Choose a Sobel kernel size\n",
    "        \n",
    "        # Choose a larger odd number to smooth gradient measurements\n",
    "        ksize = 3\n",
    "        \n",
    "        # Apply each of the thresholding functions\n",
    "        gradx = self.abs_sobel_thresh(orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "        grady = self.abs_sobel_thresh(orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "        mag_binary = self.mag_thresh(sobel_kernel=ksize, mag_thresh=(20, 100))\n",
    "        dir_binary = self.dir_thresh(sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "        blur = self.gaussian_blur(self.image)\n",
    "        canny = self.canny(blur)\n",
    "        \n",
    "        self.convert_rgb_2_hls()\n",
    "        H = self.image_hls[:,:,0]\n",
    "        L = self.image_hls[:,:,1]\n",
    "        S = self.image_hls[:,:,2]\n",
    "\n",
    "        R = self.image[:,:,0]\n",
    "        G = self.image[:,:,1]\n",
    "        B = self.image[:,:,2]\n",
    "        \n",
    "        # Binary Threshold in Color Spaces        \n",
    "        H_binary = binary_threshold_channel_flip(H)\n",
    "        L_binary = binary_threshold_channel(L)\n",
    "        S_binary = binary_threshold_channel(S)\n",
    "\n",
    "        R_binary = binary_threshold_channel(R)\n",
    "        G_binary = binary_threshold_channel(G)\n",
    "        B_binary = binary_threshold_channel(B)\n",
    "\n",
    "\n",
    "        show_image(gradx, text=\"gx\")\n",
    "        show_image(grady, text=\"gy\")\n",
    "        show_image(mag_binary, text=\"mag\")\n",
    "        show_image(dir_binary, text=\"dir\")\n",
    "\n",
    "        show_image(H_binary, text=\"H_bin\")\n",
    "        show_image(L_binary, text=\"L_bin\")\n",
    "        show_image(S_binary, text=\"S_bin\")\n",
    "        show_image(R_binary, text=\"R_bin\")\n",
    "        show_image(G_binary, text=\"G_bin\")\n",
    "        show_image(B_binary, text=\"B_bin\")\n",
    "\n",
    "        show_image(blur, text=\"blurred\")\n",
    "        show_image(canny, text=\"canny\")\n",
    "        \n",
    "        thresholded_image = ((R_binary | G_binary | L_binary) & S_binary | (gradx & G_binary & L_binary & dir_binary))\n",
    "        \n",
    "        self.image = thresholded_image\n",
    "        \n",
    "    def create_mask_corners(self):\n",
    "        xsize = self.image.shape[1]\n",
    "        ysize = self.image.shape[0] *0.99\n",
    "\n",
    "        left_bottom = [xsize*CONFIG['mask']['lb_x'], ysize*CONFIG['mask']['lb_y']]\n",
    "        right_bottom = [xsize*CONFIG['mask']['rb_x'], ysize*CONFIG['mask']['rb_y']]\n",
    "\n",
    "        left_top = [xsize*CONFIG['mask']['lt_x'], ysize*CONFIG['mask']['lt_y']]\n",
    "        right_top = [xsize*CONFIG['mask']['rt_x'], ysize*CONFIG['mask']['rt_y']]\n",
    "\n",
    "        x = [left_bottom[0], right_bottom[0], right_top[0], left_top[0], left_bottom[0]]\n",
    "        y = [left_bottom[1], right_bottom[1], right_top[1], left_top[1],  left_bottom[1]]\n",
    "        \n",
    "        self.mask_corners = np.array([i for i in zip(x,y)])\n",
    "        \n",
    "    def draw_mask(self):\n",
    "        plt.imshow(self.image,cmap=\"gray\")\n",
    "        x = self.mask_corners.T[0]\n",
    "        y = self.mask_corners.T[1]\n",
    "        plt.plot(x, y, 'r', lw=1)\n",
    "        plt.show()\n",
    "        \n",
    "    def perspective_transform(self):\n",
    "        image = self.image\n",
    "        corners = self.mask_corners\n",
    "        \n",
    "        w, h = image.shape[1::-1]\n",
    "        top = -3; bottom = 1; left = 0.3; right = 0.7\n",
    "\n",
    "        src = np.float32([corners[3],corners[2],corners[1],corners[0]])\n",
    "        dst = np.float32([[w*left, h*top],[w*right, h*top],[w*right, h*bottom],[w*left, h*bottom]])\n",
    "\n",
    "        # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "        warped = cv2.warpPerspective(image, M, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        self.image = warped\n",
    "        self.perspective_transform_matrix = M\n",
    "\n",
    "    def detect_lane_lines(self):\n",
    "        # * Detect lane pixels and fit to find the lane boundary.\n",
    "        binary_warped = self.image\n",
    "        # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((self.empty_channel, self.empty_channel, self.empty_channel))*255\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "\n",
    "        im_h, im_w = binary_warped.shape\n",
    "\n",
    "        # Set height of windows\n",
    "        window_height = np.int(im_h/nwindows)\n",
    "\n",
    "        binary_warped.nonzero()\n",
    "\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 50\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = im_h - (window+1)*window_height\n",
    "            win_y_high = im_h - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            (0,255,0), 3) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            (0,255,0), 3) \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                non_zero_x_indices_within_window = nonzerox[good_left_inds]\n",
    "                mean_within_window = np.int(np.mean(non_zero_x_indices_within_window))\n",
    "                leftx_current = mean_within_window\n",
    "\n",
    "            if len(good_right_inds) > minpix:     \n",
    "                non_zero_x_indices_within_window = nonzerox[good_right_inds]\n",
    "                mean_within_window = np.int(np.mean(non_zero_x_indices_within_window))\n",
    "                rightx_current = mean_within_window\n",
    "\n",
    "        # Flatten/Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        self.left_lane.current_fit = left_fit\n",
    "        self.right_lane.current_fit = right_fit\n",
    "        \n",
    "        self.left_lane.allx = left_fitx\n",
    "        self.left_lane.ally = ploty\n",
    "\n",
    "        self.right_lane.allx = right_fitx\n",
    "        self.right_lane.ally = ploty\n",
    "        \n",
    "        self.result_image = out_img\n",
    "        \n",
    "        self.left_lane.detected = True\n",
    "        self.right_lane.detected = True\n",
    "    \n",
    "    def detect_lane_lines_with_prior(self):\n",
    "        def superimpose_previous_lane_fit(binary_warped, fit, margin=25):\n",
    "            nonzero = binary_warped.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            y_vals = nonzeroy\n",
    "            x_vals = (fit[0]*(y_vals**2) + fit[1]*y_vals + fit[2]).astype(int)\n",
    "\n",
    "            all_y_vals = [y_vals]*margin\n",
    "            all_x_vals = []\n",
    "\n",
    "            for i, y_vals in enumerate(all_y_vals):\n",
    "                x_vals = x_vals + (i * (1 + (i%2*-2)) )\n",
    "                all_x_vals.append(x_vals)\n",
    "\n",
    "            all_x_vals = np.concatenate(all_x_vals)\n",
    "            all_y_vals = np.concatenate(all_y_vals)\n",
    "\n",
    "            binary_warped[all_y_vals, all_x_vals] = 1\n",
    "            \n",
    "            return binary_warped\n",
    "\n",
    "        binary_warped = self.image\n",
    "        left_fit = self.left_lane.current_fit\n",
    "        right_fit = self.right_lane.current_fit\n",
    "\n",
    "        # histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "        binary_warped = superimpose_previous_lane_fit(binary_warped, left_fit)\n",
    "        binary_warped = superimpose_previous_lane_fit(binary_warped, right_fit)\n",
    "\n",
    "        # super impose previous frames fit-points on the new image to influence the new fit.\n",
    "\n",
    "\n",
    "        # Finding lane lines in following frames\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 50\n",
    "\n",
    "        previous_frame_lane_x_coords = (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2]).astype(int)\n",
    "        nonzerox[previous_frame_lane_x_coords] = 1\n",
    "        left_lane_inds = (\n",
    "            (nonzerox > (previous_frame_lane_x_coords - margin)) & \n",
    "            (nonzerox < (previous_frame_lane_x_coords + margin))\n",
    "        ) \n",
    "\n",
    "        previous_frame_lane_x_coords = (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2]).astype(int)\n",
    "        nonzerox[previous_frame_lane_x_coords] = 1\n",
    "        right_lane_inds = (\n",
    "            (nonzerox > (previous_frame_lane_x_coords - margin)) & \n",
    "            (nonzerox < (previous_frame_lane_x_coords + margin))\n",
    "        )\n",
    "\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # left_fit = (left_fit * 0.1 + self.left_lane.current_fit * 0.9)\n",
    "        # right_fit = (right_fit * 0.1 + self.right_lane.current_fit * 0.9)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img = np.dstack((self.empty_channel, self.empty_channel, self.empty_channel))\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        if show_image_bool:\n",
    "            plt.imshow(out_img)\n",
    "            plt.plot(self.left_lane.allx, self.left_lane.ally, color='yellow')\n",
    "            plt.plot(self.right_lane.allx, self.right_lane.ally, color='yellow')\n",
    "\n",
    "        if not show_image_bool:\n",
    "            self.left_lane.current_fit = left_fit\n",
    "            self.right_lane.current_fit = right_fit\n",
    "\n",
    "            self.left_lane.allx = left_fitx\n",
    "            self.left_lane.ally = ploty\n",
    "\n",
    "            self.right_lane.allx = right_fitx\n",
    "            self.right_lane.ally = ploty\n",
    "\n",
    "            self.left_lane.detected = True\n",
    "            self.right_lane.detected = True\n",
    "\n",
    "        if show_image_bool:\n",
    "            plt.plot(left_fitx, ploty, color='pink')\n",
    "            plt.plot(right_fitx, ploty, color='pink')\n",
    "            plt.show()\n",
    "        \n",
    "        self.result_image = out_img        \n",
    "\n",
    "        \n",
    "    def draw_window_on_lanes(self):\n",
    "        binary_warped = self.image\n",
    "        left_fit = self.left_lane.current_fit\n",
    "        right_fit = self.right_lane.current_fit\n",
    "        \n",
    "        left_fitx = self.left_lane.allx\n",
    "        right_fitx = self.right_lane.allx\n",
    "        ploty = self.left_lane.ally\n",
    "        \n",
    "        margin=50\n",
    "        \n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                      ploty])))])\n",
    "\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        \n",
    "        window_img = np.zeros_like(self.result_image)\n",
    "        \n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (255,0, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,0,255))\n",
    "        self.result_image = cv2.addWeighted(self.result_image, 1, window_img, 1, 0)\n",
    "        \n",
    "    def plot_detected_lanes(self):\n",
    "        plt.xlim(0, self.image.shape[1])\n",
    "        plt.ylim(self.image.shape[0], 0)\n",
    "        plt.imshow(self.result_image)\n",
    "        plt.plot(self.left_lane.allx, self.left_lane.ally, color='yellow')\n",
    "        plt.plot(self.right_lane.allx, self.right_lane.ally, color='yellow')\n",
    "        plt.show()\n",
    "        \n",
    "    # * Warp the detected lane boundaries back onto the original image.\n",
    "    def warp_perspective_to_original(self):\n",
    "        binary_warped = self.image\n",
    "        left_fitx = self.left_lane.allx\n",
    "        right_fitx = self.right_lane.allx\n",
    "        ploty = self.left_lane.ally\n",
    "\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0));\n",
    "        \n",
    "        color_warp = cv2.addWeighted(self.result_image, 1, color_warp, 1, 0)\n",
    "#         color_warp = self.result_image\n",
    "\n",
    "        Minv = np.linalg.inv(self.perspective_transform_matrix)\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        image = self.original_image\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "        \n",
    "        self.image = result\n",
    "        self.result_image = result\n",
    "\n",
    "    def compute_radius_of_curvature_for_fit(self):\n",
    "        self.left_lane.radius_of_curvature = compute_radius_of_curvature(self.left_lane.current_fit, np.max(self.left_lane.ally))\n",
    "        self.right_lane.radius_of_curvature = compute_radius_of_curvature(self.right_lane.current_fit, np.max(self.right_lane.ally))\n",
    "        print(self.left_lane.radius_of_curvature, self.right_lane.radius_of_curvature)\n",
    "        # Example values: 1926.74 1908.48\n",
    "\n",
    "    def compute_radius_of_curvature_for_fit_in_meters(self):\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(self.left_lane.ally*ym_per_pix, self.left_lane.allx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(self.right_lane.ally*ym_per_pix, self.right_lane.allx*xm_per_pix, 2)\n",
    "\n",
    "        # Calculate the new radii of curvature\n",
    "        self.left_lane.radius_of_curvature = compute_radius_of_curvature(left_fit_cr, np.max(self.left_lane.ally)*ym_per_pix)\n",
    "        self.right_lane.radius_of_curvature = compute_radius_of_curvature(right_fit_cr, np.max(self.right_lane.ally)*ym_per_pix)\n",
    "\n",
    "        # Now our radius of curvature is in meters\n",
    "        print(self.left_lane.radius_of_curvature, self.right_lane.radius_of_curvature)\n",
    "        # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    def find_lanes(self, image, show=True):\n",
    "        self.read_image(image)\n",
    "\n",
    "#         self.convert_bgr_2_rgb()\n",
    "        self.show_image(text=\"RGB\")\n",
    "\n",
    "        self.undistort()\n",
    "        self.show_image(text=\"Undistorted\")\n",
    "\n",
    "        self.color_gradient_threshold_transform()\n",
    "        self.show_image(text=\"Thresholded\")\n",
    "\n",
    "        self.create_mask_corners()\n",
    "        # self.draw_mask()\n",
    "\n",
    "        self.perspective_transform()\n",
    "        self.show_image(text=\"Perspective Warped image\")\n",
    "        \n",
    "        if self.left_lane.detected and self.right_lane.detected:\n",
    "            self.detect_lane_lines_with_prior()\n",
    "        else:\n",
    "            self.detect_lane_lines()\n",
    "\n",
    "        self.draw_window_on_lanes()\n",
    "        # self.plot_detected_lanes()\n",
    "        \n",
    "#         self.compute_radius_of_curvature_for_fit_in_meters()\n",
    "\n",
    "        self.warp_perspective_to_original()\n",
    "        \n",
    "        if show:\n",
    "            self.show_image()\n",
    "            \n",
    "        return self.result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_list = os.listdir(\"./test_frames/\")\n",
    "\n",
    "if '.DS_Store' in image_list:\n",
    "    image_list.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "p = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "\n",
    "image_path = image_list[i]\n",
    "\n",
    "image = p.find_lanes(\"./test_frames/\"+image_path);\n",
    "\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_warped = np.copy(p.image)\n",
    "\n",
    "self = p\n",
    "\n",
    "binary_warped = self.image\n",
    "left_fit = self.left_lane.current_fit\n",
    "right_fit = self.right_lane.current_fit\n",
    "\n",
    "histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "y_vals = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] ).astype(int)\n",
    "x_vals = (right_fit[0]*(y_vals**2) + right_fit[1]*y_vals + right_fit[2]).astype(int)\n",
    "binary_warped = superimpose_previous_lane_fit(binary_warped, y_vals, x_vals)\n",
    "\n",
    "y_vals = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] ).astype(int)\n",
    "x_vals = (left_fit[0]*(y_vals**2) + left_fit[1]*y_vals + left_fit[2]).astype(int)\n",
    "binary_warped = superimpose_previous_lane_fit(binary_warped, y_vals, x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def superimpose_previous_lane_fit(binary_warped, y_vals, x_vals):\n",
    "    all_y_vals = [y_vals]*10\n",
    "    all_x_vals = []\n",
    "\n",
    "    for i, y_vals in enumerate(all_y_vals):\n",
    "        x_vals = x_vals + (i * (1 + (i%2*-2)) )\n",
    "        all_x_vals.append(x_vals)\n",
    "\n",
    "    all_x_vals = np.concatenate(all_x_vals)\n",
    "    all_y_vals = np.concatenate(all_y_vals)\n",
    "\n",
    "    binary_warped[all_y_vals, all_x_vals] = 1\n",
    "    \n",
    "    return binary_warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = Pipeline()\n",
    "for i in range(0,len(image_list)):\n",
    "    image_path = image_list[i]\n",
    "    p.find_lanes(\"./video_output/\"+image_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`solidWhiteRight.mp4`\n",
    "\n",
    "`solidYellowLeft.mp4`\n",
    "\n",
    "**Note: if you get an `import error` when you run the next cell, try changing your kernel (select the Kernel menu above --> Change Kernel).  Still have problems?  Try relaunching Jupyter Notebook from the terminal prompt. Also, check out [this forum post](https://carnd-forums.udacity.com/questions/22677062/answers/22677109) for more troubleshooting tips.**\n",
    "\n",
    "**If you get an error that looks like this:**\n",
    "```\n",
    "NeedDownloadError: Need ffmpeg exe. \n",
    "You can download it by calling: \n",
    "imageio.plugins.ffmpeg.download()\n",
    "```\n",
    "**Follow the instructions in the error message and check out [this forum post](https://carnd-forums.udacity.com/display/CAR/questions/26218840/import-videofileclip-error) for more troubleshooting tips across operating systems.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /Users/amoghparam/workspace/amogh/sdc/sdc_project4/output/project_video.mp4\n",
      "[MoviePy] Writing video /Users/amoghparam/workspace/amogh/sdc/sdc_project4/output/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [11:31<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /Users/amoghparam/workspace/amogh/sdc/sdc_project4/output/project_video.mp4 \n",
      "\n",
      "CPU times: user 15min 49s, sys: 1min 17s, total: 17min 7s\n",
      "Wall time: 11min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output/project_video.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from pipeline import Pipeline\n",
    "from functools import partial\n",
    "\n",
    "def gen():\n",
    "    for i in range(10,10000):\n",
    "        yield i\n",
    "        \n",
    "g = gen()\n",
    "\n",
    "def process_image(image, pipeline=None):\n",
    "    result = pipeline.find_lanes(image, show=False)\n",
    "    return result\n",
    "\n",
    "def extract_frames(image):\n",
    "    result = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite('./test_frames/frame_{}.jpg'.format(next(g)),result)\n",
    "    return result\n",
    "\n",
    "pipeline = Pipeline()\n",
    "detect_lanes = partial(process_image, pipeline=pipeline)\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "output_dir = \"./output\"\n",
    "file_name = \"project_video.mp4\"\n",
    "\n",
    "output_path = os.path.join(output_dir, file_name)\n",
    "video_output_path = os.path.realpath(output_path)\n",
    "\n",
    "output_clip = clip1.fl_image(detect_lanes)\n",
    "# output_clip = clip1.fl_image(detect_lanes).subclip(39,44)\n",
    "\n",
    "%time output_clip.write_videofile(video_output_path, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
